"""
CORTEX-12 v13 Training Script

Implements all SOTA improvements:
1. SIGReg Loss (LeJEPA) - No more collapse!
2. Ordinal Regression for Size - 54% ‚Üí 75%+ expected
3. Optional Latent Prediction Training
4. MPS Acceleration (M4 Pro GPU)

Expected Results:
- Shape: 100% (maintained)
- Color: 97%+ (SIGReg prevents collapse)
- Size: 75-85% (ordinal regression!)
- Average: 90%+ üéØ
"""

import os
import argparse
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import json
import numpy as np

# Import v13 components
from cortex_adapter_v13 import create_cortex_v13, AXIS_DIMS_V13
from sigreg_loss import HybridSIGRegContrastive
from ordinal_size_regression import HybridSizeLoss


class EnhancedDataset(Dataset):
    """Dataset for CORTEX-12 v13 training"""
    
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        
        # Load labels
        labels_path = os.path.join(data_dir, "labels_5sizes.json")
        if not os.path.exists(labels_path):
            labels_path = os.path.join(data_dir, "labels_merged.json")
        
        with open(labels_path, 'r') as f:
            self.labels = json.load(f)
        
        self.filenames = list(self.labels.keys())
        
        # Build label mappings
        shapes = sorted(set(lbl['shape'] for lbl in self.labels.values()))
        colors = sorted(set(lbl['color'] for lbl in self.labels.values()))
        sizes = sorted(set(lbl['size'] for lbl in self.labels.values()))
        
        self.shape_map = {v: i for i, v in enumerate(shapes)}
        self.color_map = {v: i for i, v in enumerate(colors)}
        self.size_map = {v: i for i, v in enumerate(sizes)}
        
        print(f"[OK] Loaded {len(self.filenames)} images")
        print(f"[OK] {len(shapes)} shapes, {len(colors)} colors, {len(sizes)} sizes")
    
    def __len__(self):
        return len(self.filenames)
    
    def __getitem__(self, idx):
        fname = self.filenames[idx]
        img_path = os.path.join(self.data_dir, "images", fname)
        img = Image.open(img_path).convert("RGB")
        
        if self.transform:
            img = self.transform(img)
        
        labels = self.labels[fname]
        
        return img, {
            'shape': self.shape_map[labels['shape']],
            'color': self.color_map[labels['color']],
            'size': self.size_map[labels['size']]
        }


def train_v13(args):
    """Main training function"""
    
    # Device setup - prioritize MPS for M4 Pro
    if args.device == 'auto':
        if torch.backends.mps.is_available():
            device = torch.device('mps')
            print("‚úÖ Using MPS (M4 Pro GPU/NPU)")
        elif torch.cuda.is_available():
            device = torch.device('cuda')
            print("‚úÖ Using CUDA")
        else:
            device = torch.device('cpu')
            print("‚ö†Ô∏è  Using CPU")
    else:
        device = torch.device(args.device)
    
    print(f"\nDevice: {device}")
    
    # Data
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    dataset = EnhancedDataset(args.data_dir, transform=transform)
    dataloader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=0,
        collate_fn=lambda b: (
            torch.stack([x[0] for x in b]),
            {k: torch.tensor([x[1][k] for x in b]) for k in b[0][1].keys()}
        )
    )
    
    # Load DINOv2 (backbone)
    print("\nLoading DINOv2 backbone...")
    dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')
    dinov2.eval()
    dinov2.to(device)
    for p in dinov2.parameters():
        p.requires_grad = False
    print("[OK] DINOv2 loaded (frozen)")
    
    # Create CORTEX v13
    print("\nCreating CORTEX-12 v13...")
    model = create_cortex_v13(
        pretrained_path=args.resume_from,
        enable_predictor=args.enable_predictor,
        device=device
    )
    model.train()
    
    # Losses
    # 1. SIGReg + Contrastive (hybrid)
    sigreg_criterion = HybridSIGRegContrastive(
        axis_dims=AXIS_DIMS_V13,
        temperature=args.temperature,
        lambda_sigreg=0.5,
        lambda_contrastive=0.5
    ).to(device)
    
    # 2. Ordinal regression for size
    size_criterion = HybridSizeLoss(
        num_classes=len(dataset.size_map),
        lambda_ordinal=0.7,
        lambda_continuous=0.3
    ).to(device)
    
    # Optimizer
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=args.lr,
        weight_decay=1e-4
    )
    
    # Scheduler
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=args.epochs, eta_min=1e-6
    )
    
    print(f"\nüöÄ Training Configuration:")
    print(f"   Epochs: {args.epochs}")
    print(f"   Batch size: {args.batch_size}")
    print(f"   Learning rate: {args.lr}")
    print(f"   Device: {device}")
    print(f"   Predictor: {args.enable_predictor}")
    print()
    
    # Training loop
    best_loss = float('inf')
    
    for epoch in range(args.epochs):
        total_sigreg = 0.0
        total_size = 0.0
        total_loss = 0.0
        
        for batch_idx, (images, labels) in enumerate(dataloader):
            images = images.to(device)
            labels_shape = labels['shape'].to(device)
            labels_color = labels['color'].to(device)
            labels_size = labels['size'].to(device)
            
            # Forward pass
            with torch.no_grad():
                features = dinov2(images)
            
            embedding, _, size_outputs = model(features)
            threshold_logits, class_probs, continuous_size = size_outputs
            
            # Loss 1: SIGReg + Contrastive (for shape, color)
            sigreg_loss, sigreg_stats = sigreg_criterion(
                embedding,
                labels_dict={
                    'shape': labels_shape,
                    'color': labels_color
                }
            )
            
            # Loss 2: Ordinal regression (for size)
            size_loss, size_stats = size_criterion(
                threshold_logits,
                continuous_size,
                labels_size
            )
            
            # Combined loss
            loss = sigreg_loss + size_loss
            
            # Backward
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            
            total_sigreg += sigreg_loss.item()
            total_size += size_loss.item()
            total_loss += loss.item()
        
        # Epoch stats
        avg_sigreg = total_sigreg / len(dataloader)
        avg_size = total_size / len(dataloader)
        avg_total = total_loss / len(dataloader)
        current_lr = optimizer.param_groups[0]['lr']
        
        print(f"Epoch {epoch+1:3d}/{args.epochs} | "
              f"SIGReg: {avg_sigreg:7.4f} | "
              f"Size: {avg_size:6.4f} | "
              f"Total: {avg_total:7.4f} | "
              f"LR: {current_lr:.2e}")
        
        scheduler.step()
        
        # Save checkpoints
        if avg_total < best_loss:
            best_loss = avg_total
            save_path = os.path.join(args.output_dir, "cortex_v13_best.pt")
            torch.save({
                'epoch': epoch + 1,
                'cortex_state_dict': model.encoder.state_dict(),
                'predictor_state_dict': model.predictor.state_dict() if model.predictor else None,
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': avg_total,
                'size_map': dataset.size_map
            }, save_path)
            print(f"  üíæ Best model: {save_path}")
        
        if (epoch + 1) % 25 == 0:
            save_path = os.path.join(args.output_dir, f"cortex_v13_{epoch+1:04d}.pt")
            torch.save({
                'epoch': epoch + 1,
                'cortex_state_dict': model.encoder.state_dict(),
                'predictor_state_dict': model.predictor.state_dict() if model.predictor else None,
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': avg_total
            }, save_path)
            print(f"  üíæ Checkpoint: {save_path}")
    
    print("\n‚úÖ Training complete!")
    print(f"   Best loss: {best_loss:.4f}")
    print(f"\nExpected improvements over v12:")
    print(f"  Shape: 100% (maintained)")
    print(f"  Color: 97%+ (SIGReg prevents collapse)")
    print(f"  Size: 75-85% (ordinal regression!)")
    print(f"  Average: 90%+ üéØ")


def main():
    parser = argparse.ArgumentParser(
        description='CORTEX-12 v13: JEPA Training with SOTA Improvements'
    )
    parser.add_argument('--data_dir', type=str, default='data/enhanced_5sizes')
    parser.add_argument('--output_dir', type=str, default='runs/cortex_v13')
    parser.add_argument('--resume_from', type=str, default=None,
                       help='Path to v12 checkpoint (optional)')
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--lr', type=float, default=1e-4)
    parser.add_argument('--temperature', type=float, default=0.1)
    parser.add_argument('--device', type=str, default='auto',
                       choices=['auto', 'cpu', 'cuda', 'mps'])
    parser.add_argument('--enable_predictor', action='store_true',
                       help='Enable latent predictor (JEPA)')
    
    args = parser.parse_args()
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("="*70)
    print("CORTEX-12 v13: JEPA Training")
    print("="*70)
    print("\nüéØ SOTA Improvements:")
    print("  1. ‚úÖ SIGReg Loss (LeJEPA)")
    print("  2. ‚úÖ Ordinal Regression for Size")
    print("  3. ‚úÖ Latent Predictor (optional)")
    print("  4. ‚úÖ MPS Acceleration")
    print()
    
    train_v13(args)


if __name__ == "__main__":
    main()
